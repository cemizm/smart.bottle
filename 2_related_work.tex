\section{Related work}
Amft, O. et al. \cite{5470653} are describing a system based on a wrist-worn inertial sensor to spot drinking motions with an accuracy of 94\%. An additional magnetic coupled sensor attached to the upper half is used to determine the relative position of the wrist-worn sensor and thereby to recognize the fluid container type and the remaining fluid level with an accuracy of 75\% respectively 72\%. The motion detection is based on a feature similarity search using euclidean distance and uses 20 features generated out of the raw sensor data.

In \cite{7038937} Dong, B. et al. are also using a bottle equipped with an inertial sensor to identify drinking events and estimate water intake. They compared 3 different machine learning algorithms to spot drinking events, whereas a neural network has comparatively the best performance with up to 99\%. The accuracy of the event detection is the result of extensive filtering and processing of the raw data before its feed to the neural network. At the same time it uses the smart phone for the identification process.

The method proposed by Yamada, Y. et al. in \cite{8229307} reaches an accuracy of up to 88\% and uses a deep neural network to estimate the water intake by means of swallowing sounds. While this approach has a low RMSE, it requires a microphone around the neck to record the swallowing sounds and the accuracy varies between subjects.